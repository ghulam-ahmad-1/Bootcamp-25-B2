{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64d0c9e3-3656-4283-99df-33c0316c7908",
   "metadata": {},
   "source": [
    "# os module – File & Directory Operations\n",
    "\n",
    "**Q:1 Create, Read, Rename, Remove files and folder**\n",
    "\n",
    "**Q:1 Get the current working directory and navigate to a sibling directory**\n",
    "\n",
    "**Q:2 Recursively list all files in a directory using only os.**\n",
    "\n",
    "**Q:3 Check if a given path is a file, directory, or doesn't exist.**\n",
    "\n",
    "**Q:4 Create a deeply nested folder structure like**\n",
    "\n",
    "**Q:5 Delete all empty directories from a given folder tree.**\n",
    "\n",
    "**Q:6 Count the number of .txt files in a directory using os.listdir().**\n",
    "\n",
    "**Q:7 Move files from one folder to another, creating the destination if needed.**\n",
    "\n",
    "**Q:8 Rename all .log files to .log.bak within a folder.**\n",
    "\n",
    "**Q:9 Print the total size of all files in a directory in MB.**\n",
    "\n",
    "**Q:10 Print the directory tree with indentation (like the tree command).**\n",
    "\n",
    "**Q:11 Write a function that synchronizes the structure of two directory trees (mirror mode).**\n",
    "\n",
    "**Q:12 Implement a safe folder deletion function that first moves the folder to a Trash directory.**\n",
    "\n",
    "**Q13: Find and print the most recently modified file in a directory recursively.**\n",
    "\n",
    "**Q:14 Generate a directory report (file count, total size, subfolders) in JSON format.**\n",
    "\n",
    "**Q:15 Track changes (additions/removals) in a directory over time using file snapshots.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9520fb42-0c72-46d2-b789-3a54618cc114",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb604f0-de66-4950-b150-3ea858f1ba9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q:1 Create, Read, Rename, Remove files and folder**\n",
    "with open(r'C:\\Users\\DELL\\Desktop\\excel\\fileee.txt','w') as f\n",
    "f.write(\"hello,\")\n",
    "\n",
    "with open(r'C:\\Users\\DELL\\Desktop\\excel\\fileee.txt','r') as f\n",
    "print(f.read())\n",
    "os.rename('fileee.txt','newfile.txt')\n",
    "os.remove('newfile.txt')\n",
    "os.mkdir('folder')\n",
    "os.rmdir('folder')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ee1aa4-67ed-41ea-b8e4-299ff1f69fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recursively list all files in a directory using only os\n",
    "def list_all_files(path):\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            print(os.path.join(root,file))\n",
    "list_all_files(r'C:\\Users\\DELL\\Desktop\\excel')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3de0b42-c67e-49e2-b0d9-225e9d3f9a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Desktop\\excel\\file1.xlsx\n",
      "C:\\Users\\DELL\\Desktop\\excel\\file2.xlsx\n",
      "C:\\Users\\DELL\\Desktop\\excel\\image.py\n",
      "C:\\Users\\DELL\\Desktop\\excel\\import pandas as pd.py\n",
      "C:\\Users\\DELL\\Desktop\\excel\\New Text Document (2).csv\n",
      "C:\\Users\\DELL\\Desktop\\excel\\New Text Document.txt\n",
      "C:\\Users\\DELL\\Desktop\\excel\\python compare_excel.py\n"
     ]
    }
   ],
   "source": [
    "#Recursively list all files in a directory using only os\n",
    "def list_all_files(path):\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            print(os.path.join(root,file))\n",
    "list_all_files(r'C:\\Users\\DELL\\Desktop\\excel')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9375de53-f7e0-4781-a449-6ad8eab91288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: C:\\Users\\DELL\\Downloads\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "print(\"Current directory:\", cwd)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aff88b7-92de-4cf0-9452-cd880199e516",
   "metadata": {},
   "outputs": [],
   "source": [
    "sibling_path = os.path.join(os.path.dirname(cwd), 'sibling_folder')\n",
    "os.chdir(sibling_path)\n",
    "print(\"Now in:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1fe3144f-c8f8-464b-b0b0-c83a0079d9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it is a directory\n"
     ]
    }
   ],
   "source": [
    "path= r'C:\\Users\\DELL\\Desktop\\excel'\n",
    "if os.path.isfile(path):\n",
    "    print('it is  a file')\n",
    "elif os.path.isdir(path):\n",
    "    print(\"it is a directory\")\n",
    "else:\n",
    "    print('path doesnt exist')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a504a41f-193c-4ea9-849a-58df15a77f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nested=os.path.join('prac1','prac2','prac3')\n",
    "os.makedirs(nested,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "73e2337b-6b7b-49fe-9931-d7c591bc141b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_dir(path):\n",
    "    for roots ,dirs, files in os.walk(path, topdown=False):\n",
    "        for d in dirs:\n",
    "            dir_path=os.path.join(roots,d)\n",
    "            if not os.listdir(dir_path):\n",
    "               os.rmdir(dir_path)\n",
    "               print('Removed:',dir_path)\n",
    "remove_dir(r\"C:\\Users\\DELL\\Desktop\\my_dataset\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7b41c41b-7da5-45e5-bfdd-476e72724bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of text files are  0\n"
     ]
    }
   ],
   "source": [
    "count=sum(1 for f in os.listdir(r\"C:\\Users\\DELL\\Desktop\\my_dataset\") if f.endswith('.txt') and os.path.isfile(f))\n",
    "print(\"number of text files are \",count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "26b0a2bb-3b00-4100-b845-86d5624a98c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "src=r'C:\\Users\\DELL\\Downloads\\prac1\\prac2'\n",
    "dest=r'C:\\Users\\DELL\\Downloads\\prac1\\prac2\\prac3'\n",
    "os.makedirs('dest',exist_ok=True)\n",
    "for file in os.listdir(src):\n",
    "    full_file= os.path.join(src,file)\n",
    "    if os.path.isfile(full_file):\n",
    "        shutil.move(full_file,dest)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "04406f76-8c61-422d-b1dc-082d6b359127",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(r'C:\\Users\\DELL\\Downloads\\prac1\\prac2'):\n",
    "                       if file.endswith('.log'):\n",
    "                           os.rename(file,file+'.bak')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2e636e-228e-43e5-8c2a-27b465e9f994",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_size = sum(os.path.getsize(os.path.join('.', f)) for f in os.listdir('.') if os.path.isfile(f))\n",
    "print(\"Total size: {:.2f} MB\".format(total_size / (1024 * 1024)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ae90520a-7168-4c28-ba04-e38cf6969d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total size 0.00 MB\n"
     ]
    }
   ],
   "source": [
    "path=r'C:\\Users\\DELL\\Downloads\\prac1\\prac2\\prac3'\n",
    "totalsize=sum(os.path.getsize(os.path.join(path,f)) for f in os.listdir(path) if os.path.isfile(f))\n",
    "print('total size {:.2f} MB'.format (totalsize/(1024*1024)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0ab3825a-334a-4720-a341-f0ea1543e7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate a directory report (file count, total size, subfolders) in JSON format\n",
    "import json\n",
    "def generate_dir_reports(path):\n",
    "    report={\n",
    "        'path': os.path.abspath(path),\n",
    "        \"file_count\" : 0,\n",
    "        \"total_size\":0,\n",
    "        \"sub_folders\": []\n",
    "        }\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        report['file_count'] +=len(files)\n",
    "        report['total_size']+= sum(os.path.getsize(os.path.join(root,f))\n",
    "        for f in files if os.path.isfile(os.path.join(root,f)))\n",
    "        if root == path:\n",
    "            report['subfolders'] = dirs\n",
    "    return report\n",
    "folder_path= path\n",
    "report= generate_dir_reports(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b7d7a2-9ca3-41b0-9a2d-1c25512f9d40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93ae0bf-78d0-4fb0-8a3e-df9e29b0596c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5791d390-e204-4c7a-8169-792bf6d02fd1",
   "metadata": {},
   "source": [
    "\n",
    "# glob module – Pattern Matching\n",
    "\n",
    "**Q:1 List all .csv and .json files in the current directory.**\n",
    "\n",
    "**Q:2 Recursively find all .jpg files in nested folders.**\n",
    "\n",
    "**Q:3 Use glob to count files grouped by extension.**\n",
    "\n",
    "**Q:4 Find files with names matching pattern report_*.txt.**\n",
    "\n",
    "**Q:5 Replace spaces with underscores in filenames found via glob.**\n",
    "\n",
    "**Q:6 Return all files with a date in the format 2025-06-*.log.**\n",
    "\n",
    "**Q:7 List all files with numeric names only (e.g., 123.txt).**\n",
    "\n",
    "**Q:8 Use glob to sort files by last modified time.**\n",
    "\n",
    "**Q:9 Find all .txt files larger than 100KB using glob and os.**\n",
    "\n",
    "**Q:10 Batch rename files with a custom suffix _archived.**\n",
    "\n",
    "**Q:11 Create a utility that indexes all media files and stores the paths in a SQLite DB.**\n",
    "\n",
    "**Q:12 Find duplicate filenames (regardless of path) across a directory tree.**\n",
    "\n",
    "**Q:13 Generate a file manifest with relative paths and hash (MD5) of contents.**\n",
    "\n",
    "**Q14: Use glob patterns dynamically to extract weekly reports (e.g., week_01.json, week_02.json).**\n",
    "\n",
    "**Q:15 Write a recursive file crawler that ignores folders listed in a .ignore file.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e086f083-8cf2-409a-99bc-423710252c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV Files: ['1decto31dec2024.csv', '3april to 23april.csv', '3marchto27march.csv', 'AAPL_stock_data.csv', 'AAPL_stock_with_sentiment.csv', 'brent_crude_data_2025-04-25.csv', 'cleaned_2000_rows (1).csv', 'cleaned_2000_rows (2).csv', 'cleaned_2000_rows.csv', 'Cleaned_AAPL_stock_data.csv', 'daily_sentiment.csv', 'dec2024.csv', 'feb3tofeb28PNG.csv', 'jan1to31.csv', 'mightymerge.io__j1igwo5i.csv', 'nov2024.csv', 'sample_conversational_dataset.csv', 'sentiment_dataset.csv', 'stock-exchange-kse-100pakistan.csv', 'Tesla_news_sentiment.csv', 'TSLA_5year_full_data.csv']\n",
      "JSON Files []\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#List all .csv and .json files in the current directory\n",
    "import glob\n",
    "csv_files= glob.glob('*.csv')\n",
    "json_files=glob.glob(\"*.json\")\n",
    "print(\"CSV Files:\", csv_files)\n",
    "print(\"JSON Files\", json_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "645efcb6-eb26-4e68-b757-768e461d75d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jpg files ['imagesvirtual.jpg', 'imatric sanad.jpg', 'IMG_20230919_231306_5 (1).jpg', 'IMG_20230919_231306_5.jpg', 'IMG_20240606_112458_551.jpg', 'inter sanad.jpg', 'istockphoto-532177250-612x612.jpg', 'my cnic.jpg', 'my domicile.jpg', 'parallel-computing-word-cloud-concept-W7HAKG.jpg', 'types-of-network-traffic.jpg', 'virtual-assistant-and-voice-recognition-vector-22000852.jpg', 'voice assistent.jpg', 'WhatsApp Image 2025-02-15 at 11.53.08_88821f56.jpg', 'ChatGPT_files\\\\unnamed.jpg', 'wordpress-5-9\\\\wordpress\\\\wp-content\\\\themes\\\\twentytwentyone\\\\assets\\\\images\\\\Daffodils.jpg', 'wordpress-5-9\\\\wordpress\\\\wp-content\\\\themes\\\\twentytwentyone\\\\assets\\\\images\\\\in-the-bois-de-boulogne.jpg', 'wordpress-5-9\\\\wordpress\\\\wp-content\\\\themes\\\\twentytwentyone\\\\assets\\\\images\\\\playing-in-the-sand.jpg', 'wordpress-5-9\\\\wordpress\\\\wp-content\\\\themes\\\\twentytwentyone\\\\assets\\\\images\\\\Reading.jpg', 'wordpress-5-9\\\\wordpress\\\\wp-content\\\\themes\\\\twentytwentyone\\\\assets\\\\images\\\\roses-tremieres-hollyhocks-1884.jpg', 'wordpress-5-9\\\\wordpress\\\\wp-content\\\\themes\\\\twentytwentyone\\\\assets\\\\images\\\\self-portrait-1885.jpg', 'wordpress-5-9\\\\wordpress\\\\wp-content\\\\themes\\\\twentytwentyone\\\\assets\\\\images\\\\the-garden-at-bougival-1884.jpg', 'wordpress-5-9\\\\wordpress\\\\wp-content\\\\themes\\\\twentytwentyone\\\\assets\\\\images\\\\villa-with-orange-trees-nice.jpg', 'wordpress-5-9\\\\wordpress\\\\wp-content\\\\themes\\\\twentytwentyone\\\\assets\\\\images\\\\young-woman-in-mauve.jpg', 'wordpress-5-9\\\\wordpress\\\\wp-content\\\\themes\\\\twentytwentytwo\\\\assets\\\\images\\\\bird-on-black.jpg', 'wordpress-5-9\\\\wordpress\\\\wp-content\\\\themes\\\\twentytwentytwo\\\\assets\\\\images\\\\bird-on-gray.jpg', 'wordpress-5-9\\\\wordpress\\\\wp-content\\\\themes\\\\twentytwentytwo\\\\assets\\\\images\\\\bird-on-green.jpg', 'wordpress-5-9\\\\wordpress\\\\wp-content\\\\themes\\\\twentytwentytwo\\\\assets\\\\images\\\\bird-on-salmon.jpg', 'wordpress-5-9\\\\wordpress\\\\wp-content\\\\themes\\\\twentytwentytwo\\\\assets\\\\images\\\\ducks.jpg', 'wordpress-5-9\\\\wordpress\\\\wp-content\\\\themes\\\\twentytwentytwo\\\\assets\\\\images\\\\flight-path-on-gray-a.jpg', 'wordpress-5-9\\\\wordpress\\\\wp-content\\\\themes\\\\twentytwentytwo\\\\assets\\\\images\\\\flight-path-on-gray-b.jpg', 'wordpress-5-9\\\\wordpress\\\\wp-content\\\\themes\\\\twentytwentytwo\\\\assets\\\\images\\\\flight-path-on-gray-c.jpg', 'wordpress-5-9\\\\wordpress\\\\wp-content\\\\themes\\\\twentytwentytwo\\\\assets\\\\images\\\\flight-path-on-salmon.jpg', 'wordpress-5-9\\\\wordpress\\\\wp-content\\\\themes\\\\twentytwentytwo\\\\assets\\\\images\\\\icon-bird.jpg']\n"
     ]
    }
   ],
   "source": [
    "# Recursively find all .jpg files in nested folders\n",
    "jpg_files=glob.glob(\"**/*.jpg\", recursive=True)\n",
    "print(\"jpg files\",jpg_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7960eb22-6d5a-478d-ae2b-7313d61d601f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'': 259}\n"
     ]
    }
   ],
   "source": [
    "# Count files grouped by extension using glob\n",
    "from collections import defaultdict\n",
    "import os \n",
    "file_groups=defaultdict(int)\n",
    "for files in glob. glob(\"*.*\"):\n",
    "    ext= os.path.splitext(file)[1]\n",
    "    file_groups[ext]+=1\n",
    "print(dict(file_groups))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a5ddb88a-132e-44ad-98a7-ef2889b90fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matching files: []\n"
     ]
    }
   ],
   "source": [
    "#Find files with names matching report_*.txt\n",
    "matcing_files= glob.glob(\"report_*.txt\")\n",
    "print('matching files:',matcing_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6944a2-6a7e-4f31-a1d3-ea519703ddf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace spaces with underscores in filenames found via glob\n",
    "for files in glob.glob(\"* *\"):\n",
    "    new_name= file.replace(\" \",\"_\")\n",
    "    os.rename(file,new_name)\n",
    "    print(f\"Renamed: {file} to {new_name}\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02f22be-8e15-4438-b6f0-89171f2cbd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return all files with a date in the format 2025-06-*.log\n",
    "date_log_files = glob.glob(\"2025-06-*.log\")\n",
    "print(\"Date-matched :\", date_log_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1347debe-d3e6-435c-9419-7c83319ea167",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List all files with numeric names only (e.g., 123.txt)\n",
    "\n",
    "import re\n",
    "\n",
    "numeric_named_files = [f for f in glob.glob(\"*.txt\") if re.fullmatch(r\"\\d+\\.txt\", f)]\n",
    "print(\"Numeric Filename Matches:\", numeric_named_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4d87d4-a7ea-4926-b1f6-98b57ef14353",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c8c4f5-ccca-4503-ab99-41e81d18576b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee706df-4370-4da5-a142-b95c9437caca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9009881-91b6-499d-be9e-5b00becf893f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf8902d-f3a0-48ad-becb-b99163059561",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b33b98-b54f-4513-a552-da8cdd53c97c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eca2f0-33d0-4cff-bc46-04ef2ec87b31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11836593-dc92-44d0-953c-46ac17571473",
   "metadata": {},
   "source": [
    "\n",
    "# File Handling – Text & Binary Files\n",
    "\n",
    "**Q:1 Count the number of lines in a file without loading it entirely.**\n",
    "\n",
    "**Q:2 Replace a specific word in a file and save it to a new file.**\n",
    "\n",
    "**Q:3 Append data to an existing file with a timestamp.**\n",
    "\n",
    "**Q:4 Read and print the first 10 lines of a file.**\n",
    "\n",
    "**Q:5 Write a list of dictionaries as CSV manually (without csv module).**\n",
    "\n",
    "**Q:6 Copy a binary file in chunks (e.g., image or PDF).**\n",
    "\n",
    "**Q:7 Write a function to compare two files and print the differing lines.**\n",
    "\n",
    "**Q:8 Safely read a file that may not exist using try-except.**\n",
    "\n",
    "**Q:9 Read a file using a specific encoding (e.g., UTF-16).**\n",
    "\n",
    "**Q:10 Detect and skip empty lines when reading a file.**\n",
    "\n",
    "**Q:11 Implement a log rotation mechanism: create log.txt, log_1.txt, etc. when size exceeds 1MB.**\n",
    "\n",
    "**Q:12 Build a file-based key-value store using JSON per line.**\n",
    "\n",
    "**Q:13 Implement version control: on every write, back up the previous version with a timestamp.**\n",
    "\n",
    "**Q:14 Create a reader that detects encoding using chardet or fallback encoding.**\n",
    "\n",
    "**Q:15 Convert a large log file into separate files per date based on timestamps in each line.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9fca21-d1a6-43c9-a323-ac90a2d11f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_count = 0\n",
    "with open('example.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        line_count += 1\n",
    "print(\"Total lines:\", line_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973c8888-d4f2-4ef3-a557-935b1c0153f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('old.txt', 'r') as f_in, open('new.txt', 'w') as f_out:\n",
    "    for line in f_in:\n",
    "        modified_line = line.replace(\"oldword\", \"newword\")\n",
    "        f_out.write(modified_line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0366559c-111f-43cd-b9cf-d5a0a57951ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "with open('log.txt', 'a') as file:\n",
    "    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    file.write(f\"[{timestamp}] Appended line here.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aeb7999-c659-452c-a71f-7f49ca9f1893",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('example.txt', 'r') as file:\n",
    "    for i, line in enumerate(file):\n",
    "        if i == 10:\n",
    "            break\n",
    "        print(line.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53751a3c-9427-4fe1-97b4-ecc3646dd2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {\"name\": \"Alice\", \"age\": 25},\n",
    "    {\"name\": \"Bob\", \"age\": 30},\n",
    "    {\"name\": \"Charlie\", \"age\": 22}\n",
    "]\n",
    "\n",
    "with open(\"output.csv\", \"w\") as f:\n",
    "    # Write header\n",
    "    headers = data[0].keys()\n",
    "    f.write(\",\".join(headers) + \"\\n\")\n",
    "\n",
    "    # Write rows\n",
    "    for row in data:\n",
    "        line = \",\".join(str(row[h]) for h in headers)\n",
    "        f.write(line + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66f88dd-9e32-44fa-acc1-d5099df1cfea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03611855-540e-4c06-b88a-9818bd7c4e1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9c5d25-b370-48a7-b94d-5d0cf1c2747e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ec443e-67c2-4aae-bf45-61348919674a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9711969f-5301-4867-b7b9-dba59247ca48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432c9462-d5ca-4f95-953c-15c9c7136de9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80361657-7f56-4534-b5f6-b7eee56ecc67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a72e9a6-e186-4d1d-b8b5-f52b3b781d59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9876fee2-bf07-4bc1-aee4-e7720ee401bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c941d47-d2a4-473e-b853-798bccd0d1d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49b7b4dc-a5af-49a8-b1a6-2629376ed791",
   "metadata": {},
   "source": [
    "\n",
    "# JSON Handling – json module\n",
    "\n",
    "**Q:1 Load JSON from a file and print a nested field (e.g., data[\"user\"][\"name\"]).**\n",
    "\n",
    "**Q:2 Write a Python dict to a file with pretty formatting.**\n",
    "\n",
    "**Q:3 Merge multiple JSON objects into a single file.**\n",
    "\n",
    "**Q:4 Convert a JSON array into CSV format.**\n",
    "\n",
    "**Q:5 Update a nested key inside a loaded JSON.**\n",
    "\n",
    "**Q:6 Create a function to pretty-print JSON from string input.**\n",
    "\n",
    "**Q:7 Safely load malformed JSON with exception handling.**\n",
    "\n",
    "**Q:8 Remove a key from each item in a JSON list and re-save.**\n",
    "\n",
    "**Q:9 Convert an object with datetime to a JSON string using a custom encoder.**\n",
    "\n",
    "**Q:10 Search for all values associated with a key in nested JSON.**\n",
    "\n",
    "**Q:11 Write a function to flatten deeply nested JSON into a flat dictionary.**\n",
    "\n",
    "**Q:12 Build a recursive JSON validator for required schema keys.**\n",
    "\n",
    "**Q:13 Convert a nested JSON into a pandas DataFrame with normalized columns.**\n",
    "\n",
    "**Q:14 Create a diff tool that compares two JSON files and shows key-level changes.**\n",
    "\n",
    "**Q:15 Handle and fix trailing commas in malformed JSON before parsing.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ed1e4b-4790-418d-ba76-3fd3697603c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('data.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "\n",
    "print(\"User name:\", data[\"user\"][\"name\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a945a883-853d-412f-b1eb-4696b812d624",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"user\": {\n",
    "        \"name\": \"Chanda\",\n",
    "        \"age\": 23,\n",
    "        \"skills\": [\"Python\", \"SQL\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('output.json', 'w') as file:\n",
    "    json.dump(data, file, indent=4, sort_keys=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea19279-5e6b-4e2b-8b55-5f1afa5bf4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "json1 = {\"id\": 1, \"name\": \"Alice\"}\n",
    "json2 = {\"id\": 2, \"name\": \"Bob\"}\n",
    "\n",
    "# Combine into a list of objects\n",
    "merged = [json1, json2]\n",
    "\n",
    "with open('merged.json', 'w') as file:\n",
    "    json.dump(merged, file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d69ea5-4a78-48b2-83e2-c02b21be9c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "combined = []\n",
    "for filename in glob.glob('*.json'):\n",
    "    with open(filename) as f:\n",
    "        combined.append(json.load(f))\n",
    "\n",
    "with open('all_merged.json', 'w') as f:\n",
    "    json.dump(combined, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "44ca8311-ecec-4810-a343-fef73c3fdda4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Alice', 'age': 30}, {'name': 'Bob', 'age': 25}]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert a JSON array into CSV format\n",
    "\n",
    "[\n",
    "    {\"name\": \"Alice\", \"age\": 30},\n",
    "    {\"name\": \"Bob\", \"age\": 25}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0ea9a5f6-031c-49d3-bbc5-165459650667",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'people.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[86], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpeople.json\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      4\u001b[0m     data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Convert to CSV manually\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'people.json'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('people.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Convert to CSV manually\n",
    "with open('people.csv', 'w') as f:\n",
    "    headers = data[0].keys()\n",
    "    f.write(\",\".join(headers) + \"\\n\")\n",
    "    for row in data:\n",
    "        f.write(\",\".join(str(row[h]) for h in headers) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29b99d1-d6e9-4fca-9c86-c9c62cb3d03b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3708f19-a270-4366-bd8e-6044a70d2989",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4462486-b8a9-492b-8c85-415a6869ac9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a38e81-21a8-4534-bf38-b56e602348cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edeaed10-eec5-450f-a8bb-ab3d9c200aa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719153bf-475c-404e-ab37-4df1bae3355d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26db1f6-d95e-4acf-9865-f30af739bdec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3306548-70c6-4a3b-8977-93d0f632d2e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22e231e-9fd0-41ea-a70d-0d0095e4665e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fb0524-fa1d-4cc8-99e6-c52f55e6f085",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3083804d-5685-4ed0-852d-40333ae26433",
   "metadata": {},
   "source": [
    "    \n",
    "# Regular Expressions – re module\n",
    "\n",
    "**Q:1 Extract email addresses from a string using re.findall().**\n",
    "\n",
    "**Q:2 Validate a US phone number using regex.**\n",
    "\n",
    "**Q:3 Extract hashtags from a tweet-like string.**\n",
    "\n",
    "**Q:4 Replace all numbers with # in a paragraph.**\n",
    "\n",
    "**Q:5 Match filenames with extension .pdf, .docx, or .xlsx.**\n",
    "\n",
    "**Q:6 Split a paragraph into sentences using regex.**\n",
    "\n",
    "**Q:7 Match a date in the format DD-MM-YYYY or YYYY/MM/DD.**\n",
    "\n",
    "**Q:8 Extract quoted strings from text (e.g., \"like this\").**\n",
    "\n",
    "**Q:9 Clean a text by removing special characters except alphanumerics and spaces.**\n",
    "\n",
    "**Q:10 Capture repeated words like the the, is is in a sentence.**\n",
    "\n",
    "**Q:11 Write a regex that extracts values from key-value pairs (key: value) even if keys contain spaces.**\n",
    "\n",
    "**Q:12 Extract nested parentheses using recursive regex (advanced feature).**\n",
    "\n",
    "**Q:13 Create a regex to detect and fix malformed URLs in a text block.**\n",
    "\n",
    "**Q:14 Build a pattern to extract address-like strings (e.g., 123 Main St, City, ZIP).**\n",
    "\n",
    "**Q:15 Tokenize a log line into timestamp, level, and message using regex groups.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df5434d-35b9-4115-b333-ace145a2bdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#q1:\n",
    "import re\n",
    "\n",
    "text = \"Contact us at support@example.com or feedback@domain.org\"\n",
    "emails = re.findall(r'[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+', text)\n",
    "print(\"Emails found:\", emails)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661df70d-da86-4263-9964-a6ac85f13087",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2:\n",
    "pattern = r'^(\\(?\\d{3}\\)?[-.\\s]?)?\\d{3}[-.\\s]?\\d{4}$'\n",
    "\n",
    "numbers = [\n",
    "    \"123-456-7890\", \"(123) 456-7890\", \"1234567890\", \"123.456.7890\", \"12345\"\n",
    "]\n",
    "\n",
    "for num in numbers:\n",
    "    if re.fullmatch(pattern, num):\n",
    "        print(f\"{num} is valid\")\n",
    "    else:\n",
    "        print(f\"{num} is invalid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d06c91-2baa-4cc3-b919-d5b66e479ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#q3:\n",
    "tweet = \"Loving the #Python and #100DaysOfCode challenge! #DevLife\"\n",
    "hashtags = re.findall(r'#\\w+', tweet)\n",
    "print(\"Hashtags:\", hashtags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b77dc7-10d4-4dd3-bff1-96221bf711cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4:\n",
    "\n",
    "paragraph = \"In 2025, Chanda completed 3 major projects and 1 internship.\"\n",
    "cleaned = re.sub(r'\\d+', '#', paragraph)\n",
    "print(\"After replacing numbers:\", cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56308ae4-1cba-4d32-93a3-6c0b6ec54047",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506b8c6c-eb88-4d2a-9ca9-a1f1fb3ace9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae3d300-1edc-48ed-8989-5a324c4e6a5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2451580-9fd8-4352-95dc-712a1bc956f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddb494a-144b-4a43-8213-519acf6e04a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f66d7a7-5d04-41d0-b569-28c958a0c8c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
